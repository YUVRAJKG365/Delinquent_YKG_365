ğŸ“Š Customer Delinquency Prediction System â€“ AI-Powered Risk Assessment & Fairness-Aware Modeling
This project presents a production-ready, end-to-end AI system that predicts customer delinquency using behavioral, financial, and demographic indicators â€“ empowered by machine learning, advanced feature engineering, and responsible AI practices. Built to support real-world decision-making for financial institutions, this project also integrates model fairness audits and bias mitigation using the Fairlearn framework.

ğŸš€ Key Features
âœ… Interactive Streamlit App for real-time risk prediction and recommendation

ğŸ” AI Model Training Pipeline using Logistic Regression and Random Forest with data balancing

ğŸ“ˆ Explainable Risk Factors like missed payments, debt-to-income ratio, credit utilization

ğŸ§  Post-processing with Fairlearn to ensure fairness across employment and location groups

ğŸ“Š Bias Auditing Dashboard â€“ Demographic Parity, Equalized Odds, and Group Metrics

ğŸ’¡ SMART Business Recommendations based on model findings

ğŸ” Ethical AI Considerations â€“ explainability, transparency, and fairness-by-design


ğŸ§ª Model Performance
Metric	Value
Accuracy	98.8%
Precision	98.8%
Recall (TPR)	98.8%
Demographic Parity Î”	0.237
Equalized Odds Î”	0.091

âœ… Post-processing with Fairlearn reduces bias while maintaining high accuracy and predictive power.

ğŸ¯ Business Use Case
This AI solution helps financial institutions like Geldium optimize their collections strategy by:

Identifying delinquency risk 3 months in advance

Enabling targeted outreach and support for high-risk customers

Reducing collections cost by up to 35%

Improving ethical and regulatory compliance in credit decisioning

ğŸ› ï¸ Tech Stack
Python (Pandas, NumPy, scikit-learn, joblib)

Streamlit â€“ Interactive app for predictions

Fairlearn â€“ Fairness auditing and bias mitigation

imbalanced-learn â€“ Class balancing (upsampling)

Jupyter Notebooks â€“ Training and exploration


ğŸ¤– Model Ethics & Explainability
This project includes a full section on responsible AI practices, including:

ğŸ“Š Bias detection across sensitive features (Employment, Location)

ğŸ§© Post-training mitigation using Equalized Odds

ğŸ“£ Transparent predictions with clear justification

ğŸ”„ Explainable outputs designed for non-technical stakeholders

ğŸ“Œ Acknowledgment
Developed by Yuvraj Kumar Gond as part of a real-world applied AI challenge, with a focus on data science, fairness, and human-centered design.
