# üìä Customer Delinquency Prediction System ‚Äì AI-Powered Risk Assessment & Fairness-Aware Modeling

A production-ready, end-to-end AI system for predicting **customer delinquency**, developed using real-world behavioral, financial, and demographic data. This system integrates **machine learning**, **bias mitigation**, and **fairness auditing** using the **Fairlearn** framework, ensuring responsible AI outcomes in high-stakes financial decisioning.

> üí° Developed by **Yuvraj Kumar Gond** as part of a real-world applied AI challenge focused on fairness, explainability, and ethical modeling in finance.

---

## üöÄ Key Features

‚úÖ **Interactive Streamlit App** ‚Äì Real-time delinquency risk prediction & business recommendations  
üîç **AI Model Pipeline** ‚Äì Trained with Logistic Regression & Random Forest; uses class balancing (SMOTE/upsampling)  
üìà **Explainable Risk Drivers** ‚Äì Missed payments, DTI ratio, credit utilization, late fees, employment status  
üß† **Fairlearn Integration** ‚Äì Ensures fairness across **employment type**, **location**, and other sensitive features  
üìä **Bias Auditing Dashboard** ‚Äì Includes Demographic Parity, Equalized Odds, and subgroup metrics  
üí° **Smart Recommendations** ‚Äì Actionable insights to guide collections and customer support teams  
üîê **Ethical AI by Design** ‚Äì Focus on fairness, transparency, and human-centered impact

---

## üß™ Model Performance

| Metric                 | Value   |
|------------------------|---------|
| Accuracy               | 88.8%   |
| Precision              | 94%   |
| Recall (TPR)           | 91%   |
| Demographic Parity Œî   | 0.237   |
| Equalized Odds Œî       | 0.091   |

‚úÖ **Fairlearn post-processing** significantly reduces bias while maintaining high predictive performance.

---

## üéØ Business Use Case

This AI solution supports financial institutions like **Geldium** in optimizing their collections and outreach strategies by:

- üîé **Identifying high-risk customers** 90 days in advance  
- üéØ **Targeting support or intervention** before default happens  
- üí∏ **Reducing collections cost** by up to 35%  
- ‚úÖ **Improving compliance** with ethical and legal AI standards  
- ü§ù **Building customer trust** through transparency and fairness

---

## üõ†Ô∏è Tech Stack

| Component         | Tools Used                             |
|------------------|----------------------------------------|
| Programming       | Python (Pandas, NumPy, scikit-learn)   |
| ML Pipeline       | Logistic Regression, Random Forest     |
| UI Interface      | Streamlit                              |
| Fairness Auditing | Fairlearn                              |
| Balancing Data    | imbalanced-learn                       |
| Persistence       | Joblib                                 |
| Exploration       | Jupyter Notebook                       |

---

## ü§ñ Model Ethics & Explainability

This project incorporates responsible AI practices:

- üìä **Bias detection** on sensitive groups (Employment Type, Location, Age)
- üß© **Post-processing with Fairlearn** using Equalized Odds
- üîç **Transparent ML predictions** with explainable reasoning
- üì£ **Human-centered design** for non-technical users to understand risk decisions

---

## üìå Acknowledgment

üß† **Developed by:** Yuvraj Kumar Gond  
üè¢ **Use Case Context:** Applied AI challenge focused on **financial fairness and responsible AI**  
üìö **Frameworks Used:** Fairlearn, Streamlit, Scikit-learn, imbalanced-learn

> If you find this project valuable, consider giving it a ‚≠ê on GitHub and sharing with your network!
